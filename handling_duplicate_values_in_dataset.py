# -*- coding: utf-8 -*-
"""Handling Duplicate Values in Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lCqZsNEdyq0x9YAHmRJR4W_S0fNA43cu

# **Removing Duplicate Data**

**BOOLEAN REMOVAL**

**Pandas duplicated() method helps in analyzing duplicate values only. It returns a boolean series which is True only for Unique elements** **bold text**
"""

# importing pandas package 
import pandas as pd 
  
# making data frame from csv file 
data = pd.read_csv("employees.csv") 
  
# sorting by first name 
data.sort_values("First Name", inplace = True) 
  
# making a bool series 
bool_series = data["First Name"].duplicated() 
  
# displaying data 
data.head() 
  
# display data 
data[bool_series]

"""Remove the duplicate values, for FALSE as op"""

# importing pandas package 
import pandas as pd 
  
# making data frame from csv file 
data = pd.read_csv("employees.csv") 
  
# sorting by first name 
data.sort_values("First Name", inplace = True) 
  
# making a bool series 
bool_series = data["First Name"].duplicated(keep = False) 
  
# bool series 
bool_series 
  
# passing NOT of bool series to see unique values only 
data = data[~bool_series] 
  
# displaying data 
data.info() 
data

"""**IDENTIFYING AND REMOVING DUPLICATES**"""

bill_data=pd.read_csv("datasets\\Telecom Data Analysis\\Bill.csv")
bill_data.shape
#Identify duplicates records in the data
dupes=bill_data.duplicated()
sum(dupes)
#Removing Duplicates
bill_data_uniq=bill_data.drop_duplicates()
bill_data_uniq.shape
#Identify duplicates in bill data based on cust_id
dupe_id=bill_data.cust_id.duplicated()
#Removing duplicates based on a variable
bill_data_cust_uniq=bill_data.drop_duplicates(['cust_id'])

bill_data_cust_uniq.shape