{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handling Duplicate Values in Dataset.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJzmdxTv9HPz"
      },
      "source": [
        "# **Removing Duplicate Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RBgIl_rj-VaT"
      },
      "source": [
        "**BOOLEAN REMOVAL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCjYc7Ri9V_h"
      },
      "source": [
        "**Pandas duplicated() method helps in analyzing duplicate values only. It returns a boolean series which is True only for Unique elements** **bold text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5h9qAk98z9k"
      },
      "source": [
        "# importing pandas package \n",
        "import pandas as pd \n",
        "  \n",
        "# making data frame from csv file \n",
        "data = pd.read_csv(\"employees.csv\") \n",
        "  \n",
        "# sorting by first name \n",
        "data.sort_values(\"First Name\", inplace = True) \n",
        "  \n",
        "# making a bool series \n",
        "bool_series = data[\"First Name\"].duplicated() \n",
        "  \n",
        "# displaying data \n",
        "data.head() \n",
        "  \n",
        "# display data \n",
        "data[bool_series] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez6MEdH19BAC"
      },
      "source": [
        "Remove the duplicate values, for FALSE as op"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA_BAP_791P9"
      },
      "source": [
        "# importing pandas package \n",
        "import pandas as pd \n",
        "  \n",
        "# making data frame from csv file \n",
        "data = pd.read_csv(\"employees.csv\") \n",
        "  \n",
        "# sorting by first name \n",
        "data.sort_values(\"First Name\", inplace = True) \n",
        "  \n",
        "# making a bool series \n",
        "bool_series = data[\"First Name\"].duplicated(keep = False) \n",
        "  \n",
        "# bool series \n",
        "bool_series \n",
        "  \n",
        "# passing NOT of bool series to see unique values only \n",
        "data = data[~bool_series] \n",
        "  \n",
        "# displaying data \n",
        "data.info() \n",
        "data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUOf0tNH-dCq"
      },
      "source": [
        "**IDENTIFYING AND REMOVING DUPLICATES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLbvEALy-r6_"
      },
      "source": [
        "bill_data=pd.read_csv(\"datasets\\\\Telecom Data Analysis\\\\Bill.csv\")\n",
        "bill_data.shape\n",
        "#Identify duplicates records in the data\n",
        "dupes=bill_data.duplicated()\n",
        "sum(dupes)\n",
        "#Removing Duplicates\n",
        "bill_data_uniq=bill_data.drop_duplicates()\n",
        "bill_data_uniq.shape\n",
        "#Identify duplicates in bill data based on cust_id\n",
        "dupe_id=bill_data.cust_id.duplicated()\n",
        "#Removing duplicates based on a variable\n",
        "bill_data_cust_uniq=bill_data.drop_duplicates(['cust_id'])\n",
        "\n",
        "bill_data_cust_uniq.shape"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}